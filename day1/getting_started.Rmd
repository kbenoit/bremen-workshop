---
title: "Getting started"
output: github_document
---

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "##",
  fig.path = "images/"
)
```


## Load the package

```{r}
library("quanteda")
```



## Reproduce example in **quanteda**

Create a text corpus:
```{r, message=FALSE}
# Create text corpus
corp <- corpus(c("A corpus is a set of documents.",
                   "This is the second document in the corpus."))
```

_Exercise: Create this corpus and get a summary using `summary(corp)`._

```{r}
summary(corp)
```

Create some tokens:
```{r}
tokens(corp)
toks <- tokens(corp, remove_punct = TRUE)
```

Create a document-feature matrix:
```{r}
dfm(toks)

toks %>%
  tokens_remove(stopwords("en")) %>%
  dfm()
```

_Question: How does the dfm change when we change the preprocessing steps?_


## Multiple ways to do the same thing

The following expressions result in the same output
```{r}
corp %>% 
    tokens()

tokens(corp)
```

and

```{r}
tokens(corp) %>%
  dfm()

dfm(corp)
```

At what stage were the word features lowercased?

